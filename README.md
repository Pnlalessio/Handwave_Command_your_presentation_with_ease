# âœ‹ Handwave  
**Command your presentation with ease**  

ğŸš€ *A web application that lets you control Google Slides presentations through natural hand gestures.*  

---

## ğŸŒŸ Project Motivation  

This project was born from two simple but powerful questions:  
1. ğŸ¤” How can we make controlling a presentation more engaging and natural, beyond traditional mouse clicks and keyboard shortcuts?  
2. ğŸŒŒ How can we control a presentation in alternative ways â€” even at a distance or in the dark?  

The answer led us to create **Handwave**, a web application that enables gesture-based interaction with **Google Slides**.  

With Handwave you can:  
- â© Move forward and backward through slides  
- âœï¸ Draw and write annotations directly on slides  
- ğŸ§¹ Erase annotations  
- ğŸ“º Toggle full-screen mode  
- ğŸ“‚ Open and close presentations  

---

## ğŸ–¥ï¸ Modes of Interaction  

Handwave offers **two control modes** to adapt to different environments:  

### 1ï¸âƒ£ Webcam Mode  
- Uses the computerâ€™s webcam to recognize hand gestures âœ‹  
- Enables **drawing and annotations** directly on slides  
- Best suited for **short/medium distances** from the computer  
- âš ï¸ Requires **good lighting conditions** (not always guaranteed in conferences with projectors)  

### 2ï¸âƒ£ Wio Terminal Mode  
- Uses a **microcontroller (Wio Terminal) with an accelerometer** ğŸ“¡  
- Allows gesture control **even at a distance** and **in the dark** ğŸŒ‘  
- âŒ Does not support the annotation feature

<p align="center">
  <img src="Immagine1.png" width="65%" />
  <img src="Immagine2.png" width="65%" />
</p>

---

## ğŸ§© Development Process  

### ğŸ” Need Finding  
Our first step was to understand usersâ€™ needs and expectations for gesture-controlled presentations.  
We conducted **interviews and questionnaires** to collect insights.  

#### Key Questions Included:  
- ğŸ‘¥ Generational and usage context of the user  
- ğŸ“Š Last time the user presented slides and in which context  
- ğŸ¯ Crucial actions for controlling a presentation  
- ğŸ˜Š Positive and negative past experiences with similar technologies  
- ğŸ”’ Privacy concerns: webcam vs. physical device  
- ğŸ’¡ Willingness to use a gesture-based web application  

---

## ğŸ‘¥ Participants  

- **Interviews:** 17 participants (9 men, 8 women), aged **15â€“59 years**  
- **Questionnaires:** 115 responses (106 Italians, 9 internationals), 66 men and 49 women  
- Most respondents aged **25â€“35 years**  

---

## ğŸ“Š Key Findings  

- âœ… Most important actions:  
  - Navigating slides (forward/backward)  
  - Annotating on slides  
  - Entering full-screen mode  
  - Opening/closing the presentation  

- ğŸ”’ Privacy:  
  - Most users had **no concern** with webcam usage  
  - Some worried about possible **data storage from the camera**  

- âš–ï¸ Preference:  
  - No clear preference between **camera-based** or **physical device-based** gesture recognition  
  - Many participants highlighted **advantages and disadvantages** of both approaches  
  - This motivated us to implement **both modes of interaction**, letting users choose the best option depending on the context  

---

## ğŸ› ï¸ Implemented Tasks  

The following core features were implemented to meet user needs:  

- â© Next slide  
- âª Previous slide  
- âœï¸ Annotate (draw) on slides  
- ğŸ§¹ Erase annotations  
- ğŸ“º Full-screen mode  
- ğŸ“‚ Open and load presentation  
- âŒ Close presentation  

Each task was visualized with a **storyboard** for clarity.  

---

## ğŸ“ Design & Prototyping  

Once the main tasks were identified, we moved to **interface design**.  
To quickly test and refine our ideas, we used:  

- ğŸ“„ **Paper Prototyping**  
- ğŸ”„ **Iterative testing** with user feedback  

This process allowed us to **gradually improve** the interface design, ensuring it was intuitive and user-friendly.  

---

## ğŸ—ï¸ Main Implementation Choices  

Handwave was developed with a focus on **simplicity**, **flexibility**, and **usability**.  

- ğŸŒ **Framework:** [Flask](https://flask.palletsprojects.com/) â€“ a lightweight and flexible Python web framework  
- ğŸ“‘ **Slides Viewer:** [Google Slides Viewer] â€“ chosen to provide users with a familiar and reliable environment  
  - Supports **pen tool for annotations**, **full-screen mode**, and **slide navigation**  
  - Fully controllable via **keyboard shortcuts**  
- ğŸ”— At application startup, users are prompted to **provide the Google Slides link** from their Google Drive, enabling them to load and interact with their presentation directly.  

---

## âœ‹ Gesture Detection via Webcam  

### ğŸ› ï¸ Libraries & Tools  
- ğŸ“· **OpenCV**: used to preprocess frames and draw a horizontal **green line** on each frame  
- ğŸ–ï¸ **MediaPipe HandDetector**:  
  - Detects the exact position of the hand  
  - Identifies **landmarks** (key points on the hand), the **hand center**, and **finger positions**  

### ğŸ¯ Workflow  
1. For every frame captured, a **green horizontal line** is drawn  
2. If the **hand center** is **above the line**, gesture control is enabled  
   - âŒ This restriction is disabled during drawing, so gestures are recognized anywhere in the camera view  
3. Gestures are mapped to **Google Slides keyboard shortcuts**  

### ğŸ–ï¸ Gesture Recognition  
- The system analyzes **which fingers are up or down**  
- Both **left and right hands** are supported  
- Each gesture is associated with a **specific action** (e.g., next slide, previous slide, annotate, erase, etc.)  
- ğŸ  Users can consult the **gesture list** both on the homepage and during presentation control  

<p align="center">
  <img src="webcam_mode.png" width="70%" />
</p>

---

## ğŸ“¡ Gesture Detection via Wio Terminal  

### ğŸ” Requirements for the Microcontroller  
We needed a device that was:  
- Equipped with an **accelerometer** (to detect speed, angle, and direction of gestures)  
- ğŸ’ª Powerful enough to run a **gesture classification model**  
- ğŸ–¥ï¸ Provided **visual feedback** through a display  
- ğŸŒ Capable of **Wi-Fi connectivity** for integration with the web app  

âœ… Final Choice: **[Wio Terminal](https://wiki.seeedstudio.com/Wio-Terminal-Getting-Started)**  
- Features all the required components  
- Programmable with **Arduino IDE**

<p align="center">
  <img src="Wio_Terminal_Mode.jpeg" width="40%" />
</p>

---

## ğŸ§  Machine Learning with Wio Terminal  

### ğŸ“Š Data Collection  
- Collected **27 minutes and 30 seconds** of accelerometer data while performing gestures  
- Data stored in **JSON files**  

### ğŸ¤– Model Training  
- Platform: [Edge Impulse](https://edgeimpulse.com/) â€“ designed for **embedded ML**  
- Training Setup:  
  - **30 epochs**  
  - **Learning rate:** 0.001  
- Results:  
  - **99% accuracy** during training  
  - **100% accuracy** on the test set (20% of dataset)  

### â˜ï¸ Cloud Integration  
- Direct cable connection was not practical (distance limitations)  
- Instead, Wio Terminal connects to **Wi-Fi** and sends the **predicted label** to the cloud in real time  
- Platform: **Blynk Cloud** â€“ free, reliable, and efficient for IoT integration  

---

## ğŸ”„ Web Application & Cloud Communication  

- Handwave makes **cyclical HTTP GET requests** to **Blynk Cloud**  
- Retrieves the **gesture label** predicted by Wio Terminal  
- Each label triggers a **Google Slides keyboard shortcut**, just like webcam-based gestures  

---

## ğŸ§ª User Testing & Evaluation  

### ğŸ“‹ Testing Approach  
- Early testing began with **paper prototypes**, allowing quick iteration  
- Evaluation Technique: **Cooperative Evaluation**  
  - Users performed tasks  
  - Thought aloud while interacting  
  - Asked questions directly to the developers  

### ğŸ‘¥ Participants  
- **15 people** tested the system  
  - 9 men, 6 women  
  - Ages **15â€“59 years**  

### â­ Results  
- Website judged as:  
  - âœ… **Intuitive**  
  - âœ… **Easy to navigate**  
- Gestures considered:  
  - âš¡ **Efficient**  
  - âš¡ **Responsive**  
- Positive feedback on **both control modes** (webcam & Wio Terminal)  

---

## Authors
- [@Pnlalessio](https://github.com/Pnlalessio)  
- [@JessicaFrabotta](https://github.com/JessicaFrabotta)

---
